{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AFRINIC Reverse Zone - EDNS Compliance Test Script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Â Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import needed modules\n",
    "import os\n",
    "import re\n",
    "import ast\n",
    "import socket\n",
    "import subprocess\n",
    "import requests\n",
    "import json\n",
    "import datetime as DT\n",
    "import dns.resolver\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Functions and base variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define DB connection details and object\n",
    "\n",
    "# Get current for for appropriate \"mconf\" file path parsing\n",
    "current_path = Path(os.getcwd())\n",
    "conf_file = current_path / \"../.db.conf\"\n",
    "\n",
    "# Define my DB Connection details from Config file\n",
    "with open(conf_file, 'r') as data_file:\n",
    "    DB_PARAMS = json.load(data_file)['afrinic_db_local']\n",
    "\n",
    "# Instantiate DB connection objects\n",
    "db_connection = psycopg2.connect(user=DB_PARAMS['USER'],\n",
    "                                 password=DB_PARAMS['PASSWD'],\n",
    "                                 host=DB_PARAMS['HOST'],\n",
    "                                 port=DB_PARAMS['PORT'],\n",
    "                                 database=DB_PARAMS['DB'])\n",
    "db_connection.autocommit = True\n",
    "db_cursor = db_connection.cursor()\n",
    "\n",
    "# Define Todays Date:\n",
    "today_date = DT.datetime.today().strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to get the list of files to be download from AFRINIC FTP\n",
    "def get_files(url, ext='', params={}):\n",
    "    response = requests.get(url, params=params)\n",
    "    if response.ok:\n",
    "        response_text = response.text\n",
    "    else:\n",
    "        return response.raise_for_status()\n",
    "    soup = BeautifulSoup(response_text, 'html.parser')\n",
    "    outfiles = [url + node.get('href') for node in soup.find_all('a')\n",
    "                if node.get('href').endswith(ext)]\n",
    "    return outfiles\n",
    "\n",
    "\n",
    "# Define function to download zones files content and segragate record types\n",
    "def process_zones(infiles: list, outfile_suffix='zoneslists', outdir='.'):\n",
    "    odir = Path.cwd() / outdir\n",
    "\n",
    "    nsfilepath4 = open(str(odir / outfile_suffix) + '.ns4', 'w')\n",
    "    nsfilepath6 = open(str(odir / outfile_suffix) + '.ns6', 'w')\n",
    "\n",
    "    dsfilepath4 = open(str(odir / outfile_suffix) + '.ds4', 'w')\n",
    "    dsfilepath6 = open(str(odir / outfile_suffix) + '.ds6', 'w')\n",
    "\n",
    "    for zone in infiles:\n",
    "        if zone.endswith('ip6.arpa-AFRINIC'):\n",
    "            r = requests.get(zone).content\n",
    "            for line in r.decode('utf-8').split('\\n'):\n",
    "                if re.search('arpa.         NS        ', line):\n",
    "                    nsfilepath6.write(line.replace(\n",
    "                        \"         NS        \", \",NS,\") + '\\n')\n",
    "                elif re.search('arpa.         DS        ', line):\n",
    "                    dsfilepath6.write(line.replace(\n",
    "                        \"         DS        \", \",DS,\") + '\\n')\n",
    "        else:\n",
    "            r = requests.get(zone).content\n",
    "            for line in r.decode('utf-8').split('\\n'):\n",
    "                if re.search('arpa.         NS        ', line):\n",
    "                    nsfilepath4.write(line.replace(\n",
    "                        \"         NS        \", \",NS,\") + '\\n')\n",
    "                elif re.search('arpa.         DS        ', line):\n",
    "                    dsfilepath4.write(line.replace(\n",
    "                        \"         DS        \", \",DS,\") + '\\n')\n",
    "    return [nsfilepath4, nsfilepath6, dsfilepath4, dsfilepath6]\n",
    "\n",
    "# Define a function to resolver nameserver into ipv4.\n",
    "\n",
    "\n",
    "def ns_resolver(ns: str):\n",
    "    try:\n",
    "        res = socket.getaddrinfo(ns, None, socket.AF_INET)[0][4][0]\n",
    "    except Exception:\n",
    "        res = 'Failed'\n",
    "    return res\n",
    "\n",
    "# Define a function to specify the resolution methods to be used.\n",
    "\n",
    "\n",
    "def ns_resolverV6(ns: str):\n",
    "    try:\n",
    "        res = socket.getaddrinfo(ns, None, socket.AF_INET6)[0][4][0]\n",
    "    except Exception:\n",
    "        res = 'Failed'\n",
    "    return res\n",
    "\n",
    "# Define function to get the list of African countries\n",
    "\n",
    "\n",
    "def get_african_countries():\n",
    "    url = 'http://country.io/continent.json'\n",
    "    open('data/country.json', 'w').write(requests.get(url,\n",
    "                                                      allow_redirects=True).content.decode(\"utf-8\"))\n",
    "    all_countries = json.load(open('data/country.json', 'r'))\n",
    "    af_cc = list()\n",
    "    for k, v in all_countries.items():\n",
    "        if v == \"AF\":\n",
    "            af_cc.append(k)  # Get African countries only\n",
    "        else:\n",
    "            pass\n",
    "    return af_cc\n",
    "\n",
    "# Define the function to extract list of NS for each ccTLDs\n",
    "\n",
    "\n",
    "def domain_ns_retrieval(domain: str):\n",
    "    try:\n",
    "        res = [ns.__str__() for ns in dns.resolver.query(domain + '.', 'NS')]\n",
    "    except Exception:\n",
    "        res = 'U'\n",
    "    return res\n",
    "\n",
    "# Define Function to insert data into DB\n",
    "\n",
    "\n",
    "def db_insert_func(data_list: list, tabname: str, columns: list):\n",
    "    try:\n",
    "        data = data_list.__str__().replace('[', '').replace(']', '')\n",
    "        cols = columns.__str__().replace(\n",
    "            '[', '').replace(']', '').replace(\"'\", \"\")\n",
    "        sql_statement = \"\"\"INSERT INTO {}({}) VALUES({})\"\"\".format(\n",
    "            tabname, cols, data)\n",
    "        db_cursor.execute(sql_statement)\n",
    "        res = True\n",
    "    except Exception:\n",
    "        res = False\n",
    "    return res\n",
    "\n",
    "\n",
    "# Define function to get ASN from Ripe web API\n",
    "def get_asn_ripe(ip_addr: str):\n",
    "    try:\n",
    "        ripe_url = 'https://stat.ripe.net/data/network-info/data.json?sourceapp=afrinic-internship-research&resource='\n",
    "        get_request = requests.get(ripe_url + ip_addr).content\n",
    "        get_req = json.loads(get_request)\n",
    "        if get_req['data']['asns']:\n",
    "            result = get_req['data']['asns'][0]\n",
    "        else:\n",
    "            result = \"Unknown\"\n",
    "    except KeyError:\n",
    "        result = \"Unknown\"\n",
    "    return result\n",
    "\n",
    "# Define function to get country of the IP from Ripe web API\n",
    "\n",
    "\n",
    "def get_country_ripe(ip_addr: str):\n",
    "    try:\n",
    "        ripe_url = 'https://stat.ripe.net/data/rir-geo/data.json?sourceapp=afrinic-internship-research&resource='\n",
    "        get_request = requests.get(ripe_url + ip_addr).content\n",
    "        get_req = json.loads(get_request)\n",
    "        if get_req['data']['located_resources']:\n",
    "            result = get_req['data']['located_resources'][0]['location']\n",
    "        else:\n",
    "            result = \"Unknown\"\n",
    "    except KeyError:\n",
    "        result = \"Unknown\"\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define EDNS Tests list\n",
    "edns_test_dict = {'dns_plain': ['dig', '+norec', '+noedns', 'soa'],\n",
    "                  'edns_plain': ['dig', '+norec', '+edns=0', 'soa'],\n",
    "                  'edns_unknw': ['dig', '+norec', '+edns=100', '+noednsneg', 'soa'],\n",
    "                  'edns_unknwopt': ['dig', '+norec', '+ednsopt=100', 'soa'],\n",
    "                  'edns_unknwflag': ['dig', '+norec', '+ednsflags=0x80', 'soa'],\n",
    "                  'edns_dnssec': ['dig', '+norec', '+dnssec', 'soa'],\n",
    "                  'edns_trunc': ['dig', '+norec', '+dnssec', '+bufsize=512', '+ignore', 'dnskey'],\n",
    "                  'edns_unknwveropt': ['dig', '+norec', '+edns=100', '+noednsneg', '+ednsopt=100', 'soa'],\n",
    "                  'edns_tcp': ['dig', '+norec', '+tcp', 'soa']}\n",
    "\n",
    "\n",
    "# Define function to execute dig command\n",
    "def run_dig_cmd(cmd: list, pkt_size=False, flag=False, aa_zone=None):\n",
    "    status = None\n",
    "    edns_version = None\n",
    "    pckt_size, flags, answer_section = None, None, None\n",
    "    result = subprocess.run(\n",
    "        cmd, stdout=subprocess.PIPE).stdout.decode('utf-8').split(';;')\n",
    "    for line in result:\n",
    "        if re.search('status:', line):\n",
    "            status = line.split(',')[1].split(':')[1].strip()\n",
    "        elif re.search('EDNS: version: 0', line):\n",
    "            edns_version = 0\n",
    "            if pkt_size:\n",
    "                pckt_size = line.split('; ')[2].split(':')[1].replace(' ','').replace('\\n','') # Get the Maximum UDP packet size\n",
    "            if flag:\n",
    "                flags =  line.split(';')[1].split(':')[3].replace('\\n','').split(' ') # Get the flags\n",
    "        elif aa_zone is not None and re.search('ANSWER SECTION', line):\n",
    "                answer_section = True if re.search(aa_zone, line) else None # Get the flags\n",
    "    return status, edns_version, pckt_size, flags, answer_section, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to run tests on NS\n",
    "def run_ednsComp_test(ns: str, df):\n",
    "    zone = df[df['NameServer'].str.match(ns)].iloc[0][0]\n",
    "    # Reset results vars\n",
    "    dns_plain, edns_plain, edns_unknw, edns_unknwopt, edns_unknwflag, edns_dnssec, edns_trunc, edns_unknwveropt, edns_tcp = False, False, False, False, False, False, False, False, False\n",
    "    packet_size = 0\n",
    "    absolute_compliant = False\n",
    "    # Test DNS plain resolution first\n",
    "    dns_plain = True if run_dig_cmd(\n",
    "        edns_test_dict['dns_plain'] + [zone, '@' + ns], aa_zone=zone)[:-1] == ('NOERROR', None, None, None, True) else False\n",
    "    if dns_plain:\n",
    "        # Test EDNS plain resolution first\n",
    "        edns_plain_test = run_dig_cmd(edns_test_dict['edns_plain'] + [zone, '@' + ns], pkt_size=True)[:-1]\n",
    "        packet_size = edns_plain_test[2]\n",
    "        edns_plain = True if edns_plain_test == ('NOERROR', 0, packet_size, None, None) else False\n",
    "        if edns_plain:\n",
    "            edns_unknw = True if run_dig_cmd(\n",
    "                edns_test_dict['edns_unknw'] + [zone, '@' + ns], aa_zone=zone)[:-1] == ('BADVERS', 0, None, None, None) else False\n",
    "            \n",
    "            edns_unknwopt = True if run_dig_cmd(\n",
    "                edns_test_dict['edns_unknwopt'] + [zone, '@' + ns], aa_zone=zone)[:-1] == ('NOERROR', 0, None, None, True) else False\n",
    "            \n",
    "            edns_unknwflag = True if run_dig_cmd(\n",
    "                edns_test_dict['edns_unknwflag'] + [zone, '@' + ns], aa_zone=zone)[:-1] == ('NOERROR', 0, None, None, True) else False\n",
    "            \n",
    "            edns_dnssec_test = run_dig_cmd(edns_test_dict['edns_dnssec'] + [zone, '@' + ns], aa_zone=zone, flag=True)[:-1]\n",
    "            if 'do' in edns_dnssec_test[3] and edns_dnssec_test[4] == True and edns_dnssec_test[0:2] == ('NOERROR', 0):\n",
    "                edns_dnssec = True\n",
    "            else:\n",
    "                edns_dnssec = False\n",
    "            \n",
    "            edns_trunc = True if run_dig_cmd(\n",
    "                edns_test_dict['edns_trunc'] + [zone, '@' + ns])[0:2] == ('NOERROR', 0) else False\n",
    "            \n",
    "            edns_unknwveropt = True if run_dig_cmd(\n",
    "                edns_test_dict['edns_unknwveropt'] + [zone, '@' + ns], aa_zone=zone)[0:2] == ('BADVERS', 0) else False\n",
    "            \n",
    "            edns_tcp = True if run_dig_cmd(\n",
    "                edns_test_dict['edns_tcp'] + [zone, '@' + ns])[0:2] == ('NOERROR', 0) else False\n",
    "    \n",
    "    t_results = [ns, dns_plain, edns_plain, edns_unknw, edns_unknwopt, edns_unknwflag, edns_dnssec, edns_trunc, edns_unknwveropt, edns_tcp, packet_size, zone]\n",
    "    \n",
    "    # Process EDNS test results for appropriate results in DB\n",
    "    f_edns_no_tcp, f_edns_tcp, f_packet_size = False, False, False\n",
    "    if t_results[1:10] == [True, True, True, True, True, True, True, True, False]:\n",
    "        f_edns_no_tcp = True\n",
    "    if t_results[1:10] == [True, True, True, True, True, True, True, True, True]:\n",
    "        f_edns_tcp = True\n",
    "    if f_edns_tcp and f_packet_size:\n",
    "        absolute_compliant = True\n",
    "    return t_results + [f_edns_no_tcp, f_edns_tcp, f_packet_size, absolute_compliant]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Script Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------- START EXECUTION ----------------------------\n",
      "    ---------------------------- START:: Download Reverse zone files & format in destination files ----------------------------\n",
      "Number of zones files to be donwnloaded: 106\n",
      "Below is the list of output files:\n",
      "/mnt/windc/Users/HP/Projects/python/afrinic_projects/edns-compliance/notebooks/../data/zoneslists.ns4\n",
      "/mnt/windc/Users/HP/Projects/python/afrinic_projects/edns-compliance/notebooks/../data/zoneslists.ns6\n",
      "/mnt/windc/Users/HP/Projects/python/afrinic_projects/edns-compliance/notebooks/../data/zoneslists.ds4\n",
      "/mnt/windc/Users/HP/Projects/python/afrinic_projects/edns-compliance/notebooks/../data/zoneslists.ds6\n",
      "    ---------------------------- END:: Download Reverse zone files & format in destination files ----------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"---------------------------- START EXECUTION ----------------------------\")\n",
    "print(\"    ---------------------------- START:: Download Reverse zone files & format in destination files ----------------------------\")\n",
    "base_url = 'http://ftp.afrinic.net/pub/zones/'\n",
    "ext = '-AFRINIC'\n",
    "zone_files = get_files(base_url, ext)\n",
    "print('Number of zones files to be donwnloaded: {}'.format(zone_files.__len__()))\n",
    "seg_list = process_zones(zone_files, outfile_suffix='zoneslists', outdir='../data')\n",
    "seg_liststr = [i.name for i in seg_list]\n",
    "print(\"Below is the list of output files:\\n{}\".format('\\n'.join(seg_liststr)))\n",
    "print(\"    ---------------------------- END:: Download Reverse zone files & format in destination files ----------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ---------------------------- START:: Load NS Ipv4 & list into pandas DataFrames ----------------------------\n",
      "    ---------------------------- END:: Load NS Ipv4 & list into pandas DataFrames ----------------------------\n"
     ]
    }
   ],
   "source": [
    "########################## Load NS Ipv4 & list into pandas DataFrames ###########################\n",
    "print(\"    ---------------------------- START:: Load NS Ipv4 & list into pandas DataFrames ----------------------------\")\n",
    "headers = ['Reverse', 'Type', 'NameServer']\n",
    "# For IPv4\n",
    "pdata = pd.read_csv(\"../data/zoneslists.ns4\", delimiter=',', names=headers, dtype=str, encoding='utf-8').drop_duplicates()\n",
    "pdata['ip_type'] = 'v4'\n",
    "# For IPv6\n",
    "pdata6 = pd.read_csv(\"../data/zoneslists.ns6\", delimiter=',', names=headers, dtype=str, encoding='utf-8').drop_duplicates()\n",
    "pdata6['ip_type'] = 'v6'\n",
    "print(\"    ---------------------------- END:: Load NS Ipv4 & list into pandas DataFrames ----------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### Insert Reverse Zone lists into DB ###########################\n",
    "print(\"    ---------------------------- START:: Insert Reverse Zone lists into DB ----------------------------\")\n",
    "# Insert Reverse Zone lists into DB\n",
    "## Ipv4\n",
    "for i in pdata.iterrows():\n",
    "    db_insert_func(data_list=[today_date] + ast.literal_eval(i[1].tolist().__str__()), tabname='edns_reverse', columns=['exec_date', 'reverse_ns', 'ns_type', 'nameserver', 'ip_type'])\n",
    "\n",
    "## Ipv6\n",
    "for i in pdata6.iterrows():\n",
    "    db_insert_func(data_list=[today_date] + ast.literal_eval(i[1].tolist().__str__()), tabname='edns_reverse', columns=['exec_date', 'reverse_ns', 'ns_type', 'nameserver', 'ip_type'])\n",
    "\n",
    "# Resolve list and Insert into DB\n",
    "ns_unique = pdata.NameServer.unique()\n",
    "ns_unique6 = pdata6.NameServer.unique()\n",
    "\n",
    "## Ipv4\n",
    "for ns in ns_unique:\n",
    "    ns_ip, ns_ipv6 = ns_resolver(ns), ns_resolverV6(ns)\n",
    "    asnv4, asnv6, ccv4, ccv6 = get_asn_ripe(ns_ip), get_asn_ripe(ns_ipv6), get_country_ripe(ns_ip), get_country_ripe(ns_ipv6)\n",
    "    db_insert_func(\n",
    "        data_list=[today_date, ns, ns_ip, ns_ipv6, asnv4, asnv6, ccv4, ccv6, 'v4'],\n",
    "        tabname='ns_resolution',\n",
    "        columns=['exec_date', 'name_server', 'ns_ip', 'ns_ipv6', 'asnv4', 'asnv6', 'ccv4', 'ccv6', 'ip_type'] )\n",
    "\n",
    "## Ipv6\n",
    "for ns in ns_unique6:\n",
    "    ns_ip, ns_ipv6 = ns_resolver(ns), ns_resolverV6(ns)\n",
    "    asnv4, asnv6, ccv4, ccv6 = get_asn_ripe(ns_ip), get_asn_ripe(ns_ipv6), get_country_ripe(ns_ip), get_country_ripe(ns_ipv6)\n",
    "    db_insert_func(\n",
    "        data_list=[today_date, ns, ns_ip, ns_ipv6, asnv4, asnv6, ccv4, ccv6, 'v6'],\n",
    "        tabname='ns_resolution',\n",
    "        columns=['exec_date', 'name_server', 'ns_ip', 'ns_ipv6', 'asnv4', 'asnv6', 'ccv4', 'ccv6', 'ip_type'] )\n",
    "\n",
    "print(\"    ---------------------------- END:: Insert Reverse Zone lists into DB ----------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### Execution of EDNS Compliance test on the Lisf of Unique Nameservers identified ###########################\n",
    "print(\"    ---------------------------- START:: Execution of EDNS Compliance test on the Lisf of Unique Nameservers identified ----------------------------\")\n",
    "# Execution of EDNS Compliance test on the Lisf of Unique Nameservers identified\n",
    "# Ipv4\n",
    "for ns in ns_unique:\n",
    "    db_insert_func(\n",
    "            data_list=[today_date] + run_ednsComp_test(ns, pdata) + ['v4'],\n",
    "            tabname='edns_tests',\n",
    "            columns=['exec_date', 'ns', 'dns_plain', 'edns_plain', 'edns_unknw', 'edns_unknwopt', \n",
    "                     'edns_unknwflag', 'edns_dnssec', 'edns_trunc', 'edns_unknwveropt', 'edns_tcp', \n",
    "                     'packet_size', 'zone', 'f_edns_no_tcp', 'f_edns_tcp', 'f_packet_size', 'absolute_compliant', \n",
    "                     'ip_type'])\n",
    "# Ipv6\n",
    "for ns in ns_unique6:\n",
    "    db_insert_func(\n",
    "            data_list=[today_date] + run_ednsComp_test(ns, pdata) + ['v4'],\n",
    "            tabname='edns_tests',\n",
    "            columns=['exec_date', 'ns', 'dns_plain', 'edns_plain', 'edns_unknw', 'edns_unknwopt', \n",
    "                     'edns_unknwflag', 'edns_dnssec', 'edns_trunc', 'edns_unknwveropt', 'edns_tcp', \n",
    "                     'packet_size', 'zone', 'f_edns_no_tcp', 'f_edns_tcp', 'f_packet_size', 'absolute_compliant', \n",
    "                     'ip_type'])\n",
    "\n",
    "print(\"    ---------------------------- END:: Execution of EDNS Compliance test on the Lisf of Unique Nameservers identified ----------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
