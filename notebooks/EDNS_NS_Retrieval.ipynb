{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDNS Compliance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T17:57:49.917428Z",
     "start_time": "2019-09-04T17:57:49.746998Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modules imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import needed modules\n",
    "import os, re, ast, socket, time, subprocess, requests, json\n",
    "import datetime as DT\n",
    "import dns.resolver\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "import pandas_profiling\n",
    "from pathlib import Path\n",
    "from bs4 import BeautifulSoup\n",
    "print('Modules imported successfully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of Basic objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get current for for appropriate \"mconf\" file path parsing\n",
    "current_path = Path(os.getcwd())\n",
    "conf_file = current_path / '..' / \".db.conf\"\n",
    "\n",
    "\n",
    "# Define my DB Connection details from Config file\n",
    "with open(conf_file, 'r') as data_file:\n",
    "    DB_PARAMS = json.load(data_file)['afrinic_db_local']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define DB connection details and object\n",
    "db_connection = psycopg2.connect(user = DB_PARAMS['USER'], password = DB_PARAMS['PASSWD'], host = DB_PARAMS['HOST'], port = DB_PARAMS['PORT'], database = DB_PARAMS['DB'])\n",
    "db_connection.autocommit = True\n",
    "db_cursor = db_connection.cursor()\n",
    "\n",
    "# Define Todays Date:\n",
    "today_date = DT.datetime.today().strftime('%Y-%m-%d') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definitions of Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T17:55:27.899290Z",
     "start_time": "2019-09-04T17:55:27.637072Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define function to get the list of files to be download from AFRINIC FTP\n",
    "def  get_files(url, ext='', params={}):\n",
    "    response = requests.get(url, params=params)\n",
    "    if response.ok:\n",
    "        response_text = response.text\n",
    "    else:\n",
    "        return response.raise_for_status()\n",
    "    soup = BeautifulSoup(response_text, 'html.parser')\n",
    "    outfiles = [url + node.get('href') for node in soup.find_all('a') if node.get('href').endswith(ext)]\n",
    "    return outfiles\n",
    "\n",
    "\n",
    "# Define function to download zones files content and segragate record types\n",
    "def process_zones(infiles: list, outfile_suffix='zoneslists', outdir='.'):\n",
    "    odir = Path.cwd() / outdir\n",
    "    \n",
    "    nsfilepath4 = open(str(odir/outfile_suffix)+'.ns4', 'w')\n",
    "    nsfilepath6 = open(str(odir/outfile_suffix)+'.ns6', 'w')\n",
    "    \n",
    "    dsfilepath4 = open(str(odir/outfile_suffix)+'.ds4', 'w')\n",
    "    dsfilepath6 = open(str(odir/outfile_suffix)+'.ds6', 'w')\n",
    "    \n",
    "    for zone in infiles:\n",
    "        if zone.endswith('ip6.arpa-AFRINIC'):\n",
    "            r = requests.get(zone).content\n",
    "            for  line in r.decode('utf-8').split('\\n'):\n",
    "                if re.search('arpa.         NS        ', line):\n",
    "                    nsfilepath6.write(line.replace(\"         NS        \", \",NS,\") + '\\n')\n",
    "                elif re.search('arpa.         DS        ', line):\n",
    "                    dsfilepath6.write(line.replace(\"         DS        \", \",DS,\") + '\\n')\n",
    "        else:\n",
    "            r = requests.get(zone).content\n",
    "            for  line in r.decode('utf-8').split('\\n'):\n",
    "                if re.search('arpa.         NS        ', line):\n",
    "                    nsfilepath4.write(line.replace(\"         NS        \", \",NS,\") + '\\n')\n",
    "                elif re.search('arpa.         DS        ', line):\n",
    "                    dsfilepath4.write(line.replace(\"         DS        \", \",DS,\") + '\\n')\n",
    "    return [nsfilepath4, nsfilepath6, dsfilepath4, dsfilepath6]\n",
    "\n",
    "# Define a function to resolver nameserver into ipv4.\n",
    "def ns_resolver(ns: str):\n",
    "    try:\n",
    "        res = socket.getaddrinfo(ns, None, socket.AF_INET)[0][4][0]\n",
    "    except:\n",
    "        res = 'Failed'\n",
    "    return res\n",
    "\n",
    "# Define a function to specify the resolution methods to be used.\n",
    "def ns_resolverV6(ns: str):\n",
    "    try:\n",
    "        res = socket.getaddrinfo(ns, None, socket.AF_INET6)[0][4][0]\n",
    "    except:\n",
    "        res = 'Failed'\n",
    "    return res\n",
    "        \n",
    "# Define function to get the list of African countries\n",
    "def get_african_countries():\n",
    "    url = 'http://country.io/continent.json'\n",
    "    open('country.json', 'w').write(requests.get(url, allow_redirects=True).content.decode(\"utf-8\"))\n",
    "    all_countries = json.load(open('country.json', 'r'))\n",
    "    af_cc = list()\n",
    "    for k, v in all_countries.items():\n",
    "        if v == \"AF\": af_cc.append(k) # Get African countries only\n",
    "        else: pass\n",
    "    return af_cc\n",
    "\n",
    "# Define the function to extract list of NS for each ccTLDs\n",
    "def domain_ns_retrieval(domain: str):\n",
    "    try:\n",
    "        res = [ns.__str__() for ns in dns.resolver.query(domain + '.', 'NS')]\n",
    "    except:\n",
    "        res = 'U'\n",
    "    return res\n",
    "\n",
    "# Define Function to insert data into DB\n",
    "def db_insert_func(data_list: list, tabname: str ,columns: list):\n",
    "    try :\n",
    "        data = data_list.__str__().replace('[','').replace(']','')\n",
    "        cols = columns.__str__().replace('[','').replace(']','').replace(\"'\",\"\")\n",
    "        sql_statement = \"\"\"INSERT INTO {}({}) VALUES({})\"\"\".format(tabname, cols, data)\n",
    "        db_cursor.execute(sql_statement)\n",
    "        res = True\n",
    "    except Exception as e:\n",
    "        res = False\n",
    "    return res\n",
    "\n",
    "\n",
    "# Define function to get ASN from Ripe web API\n",
    "def get_asn_ripe(ip_addr: str):\n",
    "    try:\n",
    "        ripe_url = 'https://stat.ripe.net/data/network-info/data.json?sourceapp=afrinic-internship-research&resource='\n",
    "        get_request = requests.get(ripe_url + ip_addr).content\n",
    "        get_req = json.loads(get_request)\n",
    "        if get_req['data']['asns']:\n",
    "            result = get_req['data']['asns'][0]\n",
    "        else:\n",
    "            result = \"Unknown\"\n",
    "    except KeyError:\n",
    "        result = \"Unknown\"\n",
    "    return result\n",
    "\n",
    "# Define function to get country of the IP from Ripe web API\n",
    "def get_country_ripe(ip_addr: str):\n",
    "    try:\n",
    "        ripe_url = 'https://stat.ripe.net/data/rir-geo/data.json?sourceapp=afrinic-internship-research&resource='\n",
    "        get_request = requests.get(ripe_url + ip_addr).content\n",
    "        get_req = json.loads(get_request)\n",
    "        if get_req['data']['located_resources']:\n",
    "            result = get_req['data']['located_resources'][0]['location']\n",
    "        else:\n",
    "            result = \"Unknown\"\n",
    "    except KeyError:\n",
    "        result = \"Unknown\"\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDNS Test Functions Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define EDNS Tests list\n",
    "edns_test_dict = {'dns_plain': ['dig', '+norec', '+noedns', 'soa']\n",
    "    ,'edns_plain': ['dig', '+norec', '+edns=0', 'soa']\n",
    "    ,'edns_unknw': ['dig', '+norec', '+edns=100', '+noednsneg', 'soa']\n",
    "    ,'edns_unknwopt': ['dig', '+norec', '+ednsopt=100', 'soa']\n",
    "    ,'edns_unknwflag': ['dig', '+norec', '+ednsflags=0x80', 'soa']\n",
    "    ,'edns_dnssec': ['dig', '+norec', '+dnssec', 'soa']\n",
    "    ,'edns_trunc': ['dig', '+norec', '+dnssec', '+bufsize=512', '+ignore', 'dnskey']\n",
    "    ,'edns_unknwveropt': ['dig', '+norec', '+edns=100', '+noednsneg', '+ednsopt=100', 'soa']\n",
    "    ,'edns_tcp': ['dig', '+norec', '+tcp', 'soa']}\n",
    "\n",
    "# Define function to execute dig command\n",
    "def run_dig_cmd(cmd: list):\n",
    "    status = None\n",
    "    edns_version = None\n",
    "    result = subprocess.run(cmd, stdout=subprocess.PIPE).stdout.decode('utf-8').split(';;')\n",
    "    for line in result:\n",
    "        if re.search('status:', line):\n",
    "             status = line.split(',')[1].split(':')[1].strip()\n",
    "        elif re.search('EDNS: version: 0', line):\n",
    "            edns_version = 0\n",
    "    return status, edns_version, result\n",
    "\n",
    "# Define function to run tests on NS\n",
    "def run_ednsComp_test(ns: str, df, cc:bool = False):\n",
    "    if cc: \n",
    "        zone  = df[df[1].str.match(ns)].iloc[0][0]\n",
    "    else: zone = df[df['NameServer'].str.match(ns)].iloc[0][0]\n",
    "    # Reset results vars\n",
    "    dns_plain, edns_plain, edns_unknw, edns_unknwopt, edns_unknwflag, edns_dnssec, edns_trunc, edns_unknwveropt, edns_tcp = 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
    "    # Test DNS plain resolution first\n",
    "    dns_plain = 1 if run_dig_cmd(edns_test_dict['dns_plain'] + [zone, '@'+ns])[0] == 'NOERROR' else 0\n",
    "    if dns_plain:\n",
    "        # Test EDNS plain resolution first\n",
    "        edns_plain = 1 if run_dig_cmd(edns_test_dict['edns_plain'] + [zone, '@'+ns])[0:2] == ('NOERROR', 0) else 0\n",
    "        if edns_plain:\n",
    "            edns_unknw = 1 if run_dig_cmd(edns_test_dict['edns_unknw'] + [zone, '@'+ns])[0:2] == ('BADVERS', 0) else 0\n",
    "            edns_unknwopt = 1 if run_dig_cmd(edns_test_dict['edns_unknwopt'] + [zone, '@'+ns])[0:2] == ('NOERROR', 0) else 0\n",
    "            edns_unknwflag = 1 if run_dig_cmd(edns_test_dict['edns_unknwflag'] + [zone, '@'+ns])[0:2] == ('NOERROR', 0) else 0\n",
    "            edns_dnssec = 1 if run_dig_cmd(edns_test_dict['edns_dnssec'] + [zone, '@'+ns])[0:2] == ('NOERROR', 0) else 0\n",
    "            edns_trunc = 1 if run_dig_cmd(edns_test_dict['edns_trunc'] + [zone, '@'+ns])[0:2] == ('NOERROR', 0) else 0\n",
    "            edns_unknwveropt = 1 if run_dig_cmd(edns_test_dict['edns_unknwveropt'] + [zone, '@'+ns])[0:2] == ('BADVERS', 0) else 0\n",
    "            edns_tcp = 1 if run_dig_cmd(edns_test_dict['edns_tcp'] + [zone, '@'+ns])[0:2] == ('NOERROR', 0) else 0\n",
    "    return [ns, dns_plain, edns_plain, edns_unknw, edns_unknwopt, edns_unknwflag, edns_dnssec, edns_trunc, edns_unknwveropt, c]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution of Main code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:59:56.020318Z",
     "start_time": "2019-09-03T16:57:04.790233Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of zones files to be donwnloaded: 106\n",
      "Below is the list of output files:\n",
      "C:\\Users\\HP\\Projects\\python\\afrinic_projects\\edns\\notebooks\\zoneslists.ns4\n",
      "C:\\Users\\HP\\Projects\\python\\afrinic_projects\\edns\\notebooks\\zoneslists.ns6\n",
      "C:\\Users\\HP\\Projects\\python\\afrinic_projects\\edns\\notebooks\\zoneslists.ds4\n",
      "C:\\Users\\HP\\Projects\\python\\afrinic_projects\\edns\\notebooks\\zoneslists.ds6\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    base_url = 'http://ftp.afrinic.net/pub/zones/'\n",
    "    ext = '-AFRINIC'\n",
    "    zone_files = get_files(base_url, ext)\n",
    "    print('Number of zones files to be donwnloaded: {}'.format(zone_files.__len__()))\n",
    "    seg_list = process_zones(zone_files, outfile_suffix='zoneslists',outdir=\"data\")\n",
    "    seg_liststr = [i.name for i in seg_list]\n",
    "    print(\"Below is the list of output files:\\n{}\".format('\\n'.join(seg_liststr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T17:03:58.630293Z",
     "start_time": "2019-09-03T17:03:58.466565Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load NS Ipv4 & list into pandas\n",
    "headers = ['Reverse', 'Type', 'NameServer']\n",
    "\n",
    "# For IPv4\n",
    "pdata = pd.read_csv(\"../data/zoneslists.ns4\", delimiter=',', names=headers, dtype=str, encoding='utf-8').drop_duplicates()\n",
    "pdata['ip_type']= 'v4'\n",
    "\n",
    "# For IPv6\n",
    "pdata6 = pd.read_csv(\"../data/zoneslists.ns6\", delimiter=',', names=headers, dtype=str, encoding='utf-8').drop_duplicates()\n",
    "pdata6['ip_type']= 'v6'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insertion of Data into DB (Reverse Zone List and Resolved NameServer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert Reverse Zone lists into DB\n",
    "## Ipv4\n",
    "for i in pdata.iterrows(): \n",
    "    db_insert_func(data_list=[today_date] + ast.literal_eval(i[1].tolist().__str__()), tabname='edns_reverse' , columns=['exec_date', 'reverse_ns', 'ns_type', 'nameserver', 'ip_type'])\n",
    "\n",
    "## Ipv6\n",
    "for i in pdata6.iterrows(): \n",
    "    db_insert_func(data_list=[today_date] + ast.literal_eval(i[1].tolist().__str__()), tabname='edns_reverse' , columns=['exec_date', 'reverse_ns', 'ns_type', 'nameserver', 'ip_type'])\n",
    "    \n",
    "# Resolve list and Insert into DB\n",
    "ns_unique = pdata.NameServer.unique()\n",
    "ns_unique6 = pdata6.NameServer.unique()\n",
    "\n",
    "## Ipv4\n",
    "for ns in ns_unique:\n",
    "    ns_ip, ns_ipv6 = ns_resolver(ns), ns_resolverV6(ns)\n",
    "    asnv4, asnv6, ccv4, ccv6 = get_asn_ripe(ns_ip), get_asn_ripe(ns_ipv6), get_country_ripe(ns_ip), get_country_ripe(ns_ipv6)\n",
    "    db_insert_func(\n",
    "        data_list=[today_date, ns, ns_ip, ns_ipv6, asnv4, asnv6, ccv4, ccv6, 'v4'],\n",
    "        tabname='ns_resolution',\n",
    "        columns=['exec_date', 'name_server', 'ns_ip', 'ns_ipv6', 'asnv4', 'asnv6', 'ccv4', 'ccv6', 'ip_type'] )\n",
    "\n",
    "## Ipv6\n",
    "for ns in ns_unique6:\n",
    "    ns_ip, ns_ipv6 = ns_resolver(ns), ns_resolverV6(ns)\n",
    "    asnv4, asnv6, ccv4, ccv6 = get_asn_ripe(ns_ip), get_asn_ripe(ns_ipv6), get_country_ripe(ns_ip), get_country_ripe(ns_ipv6)\n",
    "    db_insert_func(\n",
    "        data_list=[today_date, ns, ns_ip, ns_ipv6, asnv4, asnv6, ccv4, ccv6, 'v6'],\n",
    "        tabname='ns_resolution',\n",
    "        columns=['exec_date', 'name_server', 'ns_ip', 'ns_ipv6', 'asnv4', 'asnv6', 'ccv4', 'ccv6', 'ip_type'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution of EDNS Compliance test on the Lisf of Unique Nameservers identified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execution of EDNS Compliance test on the Lisf of Unique Nameservers identified\n",
    "# Ipv4\n",
    "for ns in ns_unique:\n",
    "    db_insert_func(\n",
    "            data_list= [today_date] + run_ednsComp_test(ns,pdata) + ['v4'], \n",
    "            tabname='edns_tests', \n",
    "            columns=['exec_date', 'ns' ,'dns_plain', 'edns_plain', 'edns_unknw', 'edns_unknwopt', 'edns_unknwflag', 'edns_dnssec', 'edns_trunc', 'edns_unknwveropt', 'edns_tcp', 'ip_type'] )\n",
    "# Ipv6\n",
    "for ns in ns_unique6:\n",
    "    db_insert_func(\n",
    "            data_list= [today_date] + run_ednsComp_test(ns,pdata6) + ['v6'], \n",
    "            tabname='edns_tests', \n",
    "            columns=['exec_date', 'ns' ,'dns_plain', 'edns_plain', 'edns_unknw', 'edns_unknwopt', 'edns_unknwflag', 'edns_dnssec', 'edns_trunc', 'edns_unknwveropt', 'edns_tcp', 'ip_type'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution of procedure for Retrieving & Testing ccTLD Name Servers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieval country codes and their respective NS & insert in DB\n",
    "data_list=[]\n",
    "for cc in get_african_countries():\n",
    "    for ns in domain_ns_retrieval(cc):\n",
    "        ns_ip, ns_ipv6 = ns_resolver(ns), ns_resolverV6(ns)\n",
    "        asnv4, asnv6, ccv4, ccv6 = get_asn_ripe(ns_ip), get_asn_ripe(ns_ipv6), get_country_ripe(ns_ip), get_country_ripe(ns_ipv6)\n",
    "        db_insert_func(\n",
    "            data_list=[today_date, cc, ns, ns_ip, ns_ipv6, asnv4, asnv6, ccv4, ccv6],\n",
    "            tabname='cctld_ns_resolution', \n",
    "            columns=['exec_date', 'countrycode', 'name_server', 'ns_ip', 'ns_ipv6', 'asnv4', 'asnv6', 'ccv4', 'ccv6'])\n",
    "        data_list.append([cc,ns])\n",
    "\n",
    "# Test EDNS Compliance for the ccTLD nameServer\n",
    "cctld_df = pd.DataFrame.from_records(data_list)\n",
    "\n",
    "for ns in cctld_df[1].unique():\n",
    "    db_insert_func(\n",
    "            data_list= [today_date] + run_ednsComp_test(ns,cctld_df, cc=True), \n",
    "            tabname='cctld_edns_tests', \n",
    "            columns=['exec_date', 'ns' ,'dns_plain', 'edns_plain', 'edns_unknw', 'edns_unknwopt', 'edns_unknwflag', 'edns_dnssec', 'edns_trunc', 'edns_unknwveropt', 'edns_tcp'] )\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The end of the Script for Testing EDNS Compliance of Afrinic Reverse Zones & ccTLDs"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "afrinic_env",
   "language": "python",
   "name": "afrinic_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
